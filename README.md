# LLM Play API

A simple Flask-based API that takes a user prompt and returns a response generated by OpenAI's GPT model. Includes auto-instrumentation support for Datadog LLM Observability.

---

## 🚀 Features

- Flask API endpoint: `/api/play`
- OpenAI `gpt-3.5-turbo` integration
- Datadog APM and LLM Observability auto-instrumentation
- Production-ready Gunicorn setup
- Dockerized

---

## 🧰 Requirements

- Python 3.11+
- OpenAI API key
- Docker (optional, but recommended)

---

## 🛠 Installation (Local)

1. **Clone this repo**:

   ```bash
   git clone https://github.com/your-org/llm-play-api.git
   cd llm-play-api
   ```

2. **Install dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

3. **Set your environment variables**:

   Create a `.env` file or export manually:

   ```env
   OPENAI_API_KEY=sk-...
   FLASK_DEBUG=true
   ```

4. **Run the app (with auto-instrumentation)**:

   ```bash
   DD_LLM_OBSERVABILITY_ENABLED=true ddtrace-run python app.py
   ```

---

## 🐳 Running with Docker

1. **Build the image**:

   ```bash
   docker build -t llm-play-app .
   ```

2. **Run the container**:

   ```bash
   docker run -p 5000:5000 -e OPENAI_API_KEY=sk-... llm-play-app
   ```
   Use docker compose to build the llm application along with the datadog-agent to enable llm observability.
   ```
   docker compose up --build
   ```
---

## 🔌 API Usage

**Endpoint**: `POST /api/play`

### Request

```json
{
  "prompt": "Tell me a joke about databases."
}
```

### Response

```json
{
  "response": "Why did the SQL query cross the road? To join the other table."
}
```

---

## 📊 Datadog Integration

This project supports **Datadog LLM Observability**:

- Automatically traces OpenAI calls
- Tracks token usage, latency, cost
- Adds `llm.*` tags to traces

### Requirements

- `ddtrace==3.10.2`
- `datadog-llm>=0.2`
- Launch with `ddtrace-run`
- Set: `DD_LLM_OBSERVABILITY_ENABLED=true`

---

## 🔐 Environment Variables

| Variable                     | Description                        |
|------------------------------|------------------------------------|
| `OPENAI_API_KEY`             | Your OpenAI API key                |
| `FLASK_DEBUG`                | Enable Flask debug mode (optional) |
| `DD_LLM_OBSERVABILITY_ENABLED` | Enable Datadog LLM tracing         |

---

## 🧪 Development Tips

- To simulate latency, set:
  ```env
  CHAOS_ON=true
  ```
- To run with Gunicorn locally:
  ```bash
  DD_LLM_OBSERVABILITY_ENABLED=true ddtrace-run gunicorn -w 2 -b 0.0.0.0:5000 app:app
  ```

---

## 📁 Project Structure

```
.
├── app.py
├── Dockerfile
├── requirements.txt
└── README.md
```

---

## 📝 License

MIT or your preferred license.
